{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### MLP Classifier\n",
    "\n",
    "#### 20171181 최영빈\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   제공되는 데이터셋인 iris 데이터셋 세팅\n",
    "\n",
    "-   훈련 데이터셋과 테스트 데이터셋 분리\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "iris_dataset= datasets.load_iris()\n",
    "x=iris_dataset.data\n",
    "y=iris_dataset.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   Classifier 설정 (층당 뉴런 수 5개, 은닉층 2층 / 최대반복 100회)\n",
    "-   해당 Classifier 훈련 후 테스트셋으로 시험 후 accuracy score 출력\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(\n",
    "    5, 2), random_state=3, max_iter=100)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "predicted = classifier.predict(x_test)\n",
    "\n",
    "print('뉴런 수 5, 은닉층 수 2, 반복횟수 100회')\n",
    "print(predicted)\n",
    "print(y_test)\n",
    "print(accuracy_score(y_test, predicted))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "뉴런 수 5, 은닉층 수 2, 반복횟수 100회\n",
      "[0 2 2 0 0 2 2 0 0 2 2 0 2 2 2 2 2 2 0 0 2 2 2 0 2 2 0 0 2 2]\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2]\n",
      "0.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfcv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   뉴런5개, 층2개 반복100회의 설정으로는 정확도가 0.5밖에 되지 않음\n",
    "\n",
    "-   다른 설정은 두고 뉴런의 수만 2배로 늘렸을때의 결과\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(\n",
    "    10, 2), random_state=3, max_iter=100)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "predicted = classifier.predict(x_test)\n",
    "\n",
    "print('뉴런 수 10, 은닉층 수 2, 반복횟수 100회')\n",
    "print(predicted)\n",
    "print(y_test)\n",
    "print(accuracy_score(y_test, predicted))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "뉴런 수 10, 은닉층 수 2, 반복횟수 100회\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2]\n",
      "0.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfcv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   오히려 정확도가 0.2로 줄어든 상태.\n",
    "-   무작정 늘린 뉴런은 오히려 성능을 더 저하시킬 수 있음.\n",
    "\n",
    "-   뉴런의 수는 5개이고 층 수를 2개에서 5개로 늘렸을때의 결과\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(\n",
    "    5, 5), random_state=3, max_iter=100)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "predicted = classifier.predict(x_test)\n",
    "\n",
    "print('뉴런 수 5, 은닉층 수 5, 반복횟수 100회')\n",
    "print(predicted)\n",
    "print(y_test)\n",
    "print(accuracy_score(y_test, predicted))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "뉴런 수 5, 은닉층 수 5, 반복횟수 100회\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2]\n",
      "0.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfcv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   뉴런을 늘렸을때와 비슷하게 성능이 오히려 더 하락함.\n",
    "\n",
    "-   반복 횟수를 증가시켰을 때의 결과\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(\n",
    "    5, 2), random_state=3, max_iter=1000)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "predicted = classifier.predict(x_test)\n",
    "\n",
    "print('뉴런 수 5, 은닉층 수 2, 반복횟수 1000회')\n",
    "print(predicted)\n",
    "print(y_test)\n",
    "print(accuracy_score(y_test, predicted))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "뉴런 수 5, 은닉층 수 2, 반복횟수 1000회\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 2 1 1 0 2 1 0 0 1 2]\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2]\n",
      "0.9666666666666667\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfcv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   반복횟수를 늘렸을 때 성능이 비약적으로 상승.\n",
    "\n",
    "-   반복횟수가 늘었을 때 뉴런의 수, 은닉층의 수 중 하나만 늘어났을 때의 결과는?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(\n",
    "    10, 2), random_state=3, max_iter=1000)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "predicted = classifier.predict(x_test)\n",
    "\n",
    "print('뉴런 수 10, 은닉층 수 2, 반복횟수 1000회')\n",
    "print(predicted)\n",
    "print(y_test)\n",
    "print(accuracy_score(y_test, predicted))\n",
    "\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(\n",
    "    5, 5), random_state=3, max_iter=1000)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "predicted = classifier.predict(x_test)\n",
    "\n",
    "print('뉴런 수 5, 은닉층 수 5, 반복횟수 1000회')\n",
    "print(predicted)\n",
    "print(y_test)\n",
    "print(accuracy_score(y_test, predicted))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "뉴런 수 10, 은닉층 수 2, 반복횟수 1000회\n",
      "[0 2 2 0 2 2 2 0 0 2 2 0 2 2 2 0 2 2 0 0 2 2 2 0 2 2 0 0 2 2]\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2]\n",
      "0.5666666666666667\n",
      "뉴런 수 5, 은닉층 수 5, 반복횟수 1000회\n",
      "[0 1 2 0 2 2 2 0 0 2 1 0 2 2 2 0 1 2 0 0 1 2 2 0 2 1 0 0 2 2]\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2]\n",
      "0.7333333333333333\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfcv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   뉴런5, 층2개일때보다 성능이 하락하는 모습을 볼 수 있음.\n",
    "-   뉴런과 층수를 둘 다 같이 증가시켰을 때는?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(\n",
    "    10, 5), random_state=3, max_iter=1000)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "predicted = classifier.predict(x_test)\n",
    "\n",
    "print('뉴런 수 10, 은닉층 수 5, 반복횟수 1000회')\n",
    "print(predicted)\n",
    "print(y_test)\n",
    "print(accuracy_score(y_test, predicted))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "뉴런 수 10, 은닉층 수 5, 반복횟수 1000회\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2]\n",
      "[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2]\n",
      "1.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfcv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   뉴런의 수와 은닉층의 수를 조화롭게 상승시킬 경우 성능이 상승하는것을 확인 가능.\n",
    "\n",
    "-   여러가지를 시도해보며 데이터에 알맞는 뉴런의 수와 은닉층의 수, 반복횟수를 찾는것이 중요."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MLP Regressor\n",
    "\n",
    "#### 20171181 최영빈\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   테스트에 사용할 boston dataset load 후 테스트셋, 훈련셋 분리"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "boston_dataset = datasets.load_boston()\n",
    "x = boston_dataset.data\n",
    "y = boston_dataset.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfcv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this case special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows:\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and:\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   뉴런 수 5, 은닉층 2개로 100회 반복으로 훈련 후 결과의 squared error측정 후 출력"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "classifier = MLPRegressor(hidden_layer_sizes=(\n",
    "    5, 2), max_iter=100, random_state=1)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "predicted = classifier.predict(x_test)\n",
    "mse = mean_squared_error(y_test, predicted)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('뉴런 수 5, 은닉층 수 2, 반복횟수 100회')\n",
    "print(\"RMSE : \", rmse)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "뉴런 수 5, 은닉층 수 2, 반복횟수 100회\n",
      "RMSE :  30.685723271739235\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tfcv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   위의 Classifier처럼 뉴런과 은닉층을 조화롭게 증가시키고, 반복횟수를 증가시킨 결과"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "classifier = MLPRegressor(hidden_layer_sizes=(\n",
    "    10, 5), max_iter=1000, random_state=1)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "predicted = classifier.predict(x_test)\n",
    "mse = mean_squared_error(y_test, predicted)\n",
    "rmse = np.sqrt(mse)\n",
    "# 결과 출력\n",
    "\n",
    "print('뉴런 수 10, 은닉층 수 5, 반복횟수 1000회')\n",
    "print(\"RMSE : \", rmse)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "뉴런 수 10, 은닉층 수 5, 반복횟수 1000회\n",
      "RMSE :  10.062802851376716\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   성능이 확실하게 증가하는 것을 확인할 수 있다.\n",
    "\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.12 64-bit ('tfcv': conda)"
  },
  "interpreter": {
   "hash": "30740838fbad623b12890ad10976683e42e46a003fa18980ca1f6ad85db8810b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}